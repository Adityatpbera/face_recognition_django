{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The counter is 1\n",
      "No faces found in the provided images.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv\n",
    "import cv2\n",
    "import pytesseract\n",
    "import PIL\n",
    "import pyzbar\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import face_recognition\n",
    "import \n",
    "from PIL import Image\n",
    "\n",
    "# Load the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Set input and output directories\n",
    "input_directory = \"F:/Images/PAN images/Input\"\n",
    "output_directory = \"F:/Images/PAN images/Output\"\n",
    "\n",
    "os.makedirs(input_directory, exist_ok = True)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "image_files = os.listdir(input_directory)\n",
    "\n",
    "for filename in image_files:\n",
    "    if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(input_directory, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=0, minSize=(30, 30))\n",
    "        counter = 0\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # Add some padding to the face region\n",
    "            padding = 10\n",
    "            x -= padding\n",
    "            y -= padding\n",
    "            w += padding * 3\n",
    "            h += padding * 3\n",
    "            \n",
    "            # Ensure the cropped region is within the image boundaries\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            w = min(w, image.shape[1] - x)\n",
    "            h = min(h, image.shape[0] - y)\n",
    "            \n",
    "            # Crop the face region from the image\n",
    "            face = image[y:y+h, x:x+w]\n",
    "\n",
    "            #Display the cropped face\n",
    "            cv2.imshow('Cropped Face', face)\n",
    "            cv2.waitKey(2000)\n",
    "            \n",
    "            counter = 0\n",
    "            counter += 1\n",
    "            print(f\"The counter is {counter}\")\n",
    "            # break\n",
    "            # Save the cropped face to the output directory\n",
    "            output_path = os.path.join(output_directory, f\"cropped_face_{counter}.jpg\")\n",
    "            cv2.imwrite(output_path, face)\n",
    "            def match_faces(id_card_image, ref_image):\n",
    "                id_card = face_recognition.load_image_file(id_card_image)\n",
    "                ref = face_recognition.load_image_file(ref_image)\n",
    "\n",
    "                id_card_encodings = face_recognition.face_encodings(id_card)\n",
    "                ref_encodings = face_recognition.face_encodings(ref)\n",
    "\n",
    "                if len(id_card_encodings) == 0 or len(ref_encodings) == 0:\n",
    "                    print(\"No faces found in the provided images.\")\n",
    "                    return\n",
    "\n",
    "                id_card_encoding = id_card_encodings[0]\n",
    "                ref_encoding = ref_encodings[0]\n",
    "\n",
    "                results = face_recognition.compare_faces([id_card_encoding], ref_encoding)\n",
    "                similarity = face_recognition.face_distance([id_card_encoding], ref_encoding)\n",
    "                similarity_percent = (1 - similarity[0]) * 100\n",
    "\n",
    "                if results[0]:\n",
    "                    print(\"Faces match with a similarity of {:.2f}%.\".format(similarity_percent))\n",
    "                else:\n",
    "                    print(\"Faces do not match.\")\n",
    "                 \n",
    "                print(f\"The counter is {counter}\")\n",
    "            break  # Uncomment this line if you only want to process the first detected face\n",
    "        # Save the processed image with rectangles around the faces (optional)\n",
    "        output_image_path = os.path.join(output_directory, filename)\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "    else:\n",
    "        print(\"No output\")\n",
    "    break\n",
    "\n",
    "# Provide the paths to your ID card and referral images\n",
    "id_card_image_path = output_path\n",
    "\n",
    "input_directory_selfies = \"F:\\Images\\Single_selfie\"\n",
    "os.makedirs(input_directory_selfies, exist_ok = True)\n",
    "input_selfies = os.listdir(input_directory_selfies)\n",
    "for filename in input_selfies:\n",
    "    if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(input_directory_selfies, filename)\n",
    "        ref_image_path = image_path\n",
    "\n",
    "match_faces(output_image_path, ref_image_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
